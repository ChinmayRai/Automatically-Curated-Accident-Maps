#	crawl article urls from the web and classify them: scrape_classify.py
#	get the body of the articles in desired format(seperate reporting Location): urlToBody.py
#	tokenize the body of articles into sentences : body_to_sent.py
#	preprocessing before feeding into openie : sent_to_openie.py (this itself uses cleaner.py)

#	****_openie_input.txt  ----openie---> ****_openie_output.txt

#	filter out relevant sentences from the body : sent_selector7.py

